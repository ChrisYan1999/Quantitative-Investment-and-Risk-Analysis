{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project #2: Time Series Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project #2: Time Series Model by Chris Yu Yan\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import pandas_datareader.data as web\n",
    "import statsmodels.api as sm\n",
    "from itertools import combinations   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "card_data = pd.read_excel('/Users/alukadawn/Desktop/Columbia/2024 Fall/CRA/Projects/Project #2 -Time Series Model/card.xlsx')\n",
    "cre_data = pd.read_excel('/Users/alukadawn/Desktop/Columbia/2024 Fall/CRA/Projects/Project #2 -Time Series Model/CRE.xlsx')\n",
    "card_data = pd.DataFrame(card_data)\n",
    "cre_data = pd.DataFrame(cre_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the card and cre data into charge-off percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "card_data['card_chargeoff_pct'] = (card_data['chargeoffs'] / card_data['loans'])\n",
    "cre_data['cre_chargeoff_pct'] = (cre_data['chargeoffs'] / cre_data['loans'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use ADF to test stationarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Card Charge-Off ADF Statistic: -2.836318810006879, p-value: 0.053270234034481015',\n",
       " 'CRE Charge-Off ADF Statistic: -1.58897552846476, p-value: 0.4891290849010973')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "card_adf_result = adfuller(card_data['card_chargeoff_pct'])\n",
    "cre_adf_result = adfuller(cre_data['cre_chargeoff_pct'])\n",
    "\n",
    "card_adf_statistic = card_adf_result[0]\n",
    "card_adf_p_value = card_adf_result[1]\n",
    "\n",
    "cre_adf_statistic = cre_adf_result[0]\n",
    "cre_adf_p_value = cre_adf_result[1]\n",
    "\n",
    "card_adf_output = f\"Card Charge-Off ADF Statistic: {card_adf_statistic}, p-value: {card_adf_p_value}\"\n",
    "cre_adf_output = f\"CRE Charge-Off ADF Statistic: {cre_adf_statistic}, p-value: {cre_adf_p_value}\"\n",
    "(card_adf_output, cre_adf_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both data have p-value greater than 0.05, indicating non-stationarity.\n",
    "However, the card data is only slightly above the 5% threshold, meaning the test is not quite rejecting the null hypothesis of non-stationarity. \n",
    "\n",
    "\n",
    "Therefore, we will proceed to treat the card data as stationary and take the difference of the cre data to improve stationarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CRE Charge-Off ADF Statistic: -3.332627529259299, p-value: 0.013481545256871296'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cre_data['cre_chargeoff_pct'] = cre_data['cre_chargeoff_pct'].diff()\n",
    "\n",
    "cre_adf_result = adfuller(cre_data['cre_chargeoff_pct'][~cre_data['cre_chargeoff_pct'].isna()])\n",
    "\n",
    "cre_adf_statistic = cre_adf_result[0]\n",
    "cre_adf_p_value = cre_adf_result[1]\n",
    "\n",
    "cre_adf_output = f\"CRE Charge-Off ADF Statistic: {cre_adf_statistic}, p-value: {cre_adf_p_value}\"\n",
    "cre_adf_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cre data is stationary after taking the first difference and the p-value from ADF test is less than 0.05. Now we can proceed with further calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download unemployment data (UNRATE), oil prices (DCOILBRENTEU), US GDP (GDP), 10-year minus 2-year treasury rates (T10Y2Y), and a volatility series of your choice. Here we will go with VIX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "unrate = web.DataReader(\"UNRATE\", \"fred\", start = '2000-01-01')\n",
    "oil_price = web.DataReader('DCOILBRENTEU', \"fred\", start = '2000-01-01')\n",
    "gdp = web.DataReader(\"GDP\", \"fred\", start = '2000-01-01')\n",
    "t10y2y = web.DataReader('T10Y2Y', 'fred', start = '2000-01-01')\n",
    "vix = web.DataReader('VIXCLS', 'fred', start = '2000-01-01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pull the economic data into a pandas data frame and find the ADF test statistics, adjust the data accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3498738676195984"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The unrate data is monthly on the first of the month, so we will adjust the data to match the datetime.\n",
    "unrate['date'] = [x.date() - dt.timedelta(days=1) for x in unrate.index]\n",
    "unrate = unrate[unrate['date'] <= dt.date(2020,1,1)]\n",
    "unrate['year'] = [x.year for x in unrate.date]\n",
    "unrate['month'] = [x.month for x in unrate.date]\n",
    "unrate = unrate[~unrate.UNRATE.isna()]\n",
    "unrate = unrate[unrate.month.isin([3,6,9,12])]\n",
    "unrate_adf_p_value = adfuller(unrate.UNRATE)[1]\n",
    "unrate_adf_p_value \n",
    "# It's not stationary, so we will take the first difference to make it stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011544625714323992"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unrate['UNRATE'] = unrate['UNRATE'].diff()\n",
    "unrate = unrate[~unrate.UNRATE.isna()]\n",
    "unrate_adf_p_value = adfuller(unrate.UNRATE)[1]\n",
    "unrate_adf_p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have done with the adjustment for unrate and checked its stationarity, let's proceed to other data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4730305410138694e-13"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Oil Price\n",
    "oil_price['date'] = [x.date() - dt.timedelta(days=1) for x in oil_price.index]\n",
    "oil_price = oil_price[oil_price['date'] <= dt.date(2020, 1, 1)]\n",
    "oil_price['year'] = [x.year for x in oil_price.date]\n",
    "oil_price['month'] = [x.month for x in oil_price.date]\n",
    "oil_price['day'] = [x.day for x in oil_price.date]\n",
    "oil_price = oil_price.resample('ME').last()\n",
    "oil_price = oil_price[~oil_price.DCOILBRENTEU.isna()]\n",
    "oil_price = oil_price[oil_price.month.isin([3,6,9,12])]\n",
    "# We tried to us .diff() but the data appears to be very messy because it was observed on a daily basis,\n",
    "# so we will try a lag now.\n",
    "oil_price['oil_price_lag'] = oil_price.DCOILBRENTEU.shift()\n",
    "oil_price['oil_price_growth'] = (oil_price.DCOILBRENTEU - oil_price.oil_price_lag)/oil_price.oil_price_lag\n",
    "oil_price = oil_price[~oil_price.oil_price_growth.isna()]\n",
    "oil_price_adf_p_value = adfuller(oil_price.oil_price_growth)[1]\n",
    "oil_price_adf_p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a GDP growth variable (GDP_t â€“ GDP_t-1) / GDP_t-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.035206322282689e-06"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# US GDP\n",
    "gdp['date'] = [x.date() - dt.timedelta(days=1) for x in gdp.index]\n",
    "gdp = gdp[gdp.date <= dt.date(2020, 1, 1)]\n",
    "gdp['month'] = [x.month for x in gdp.date]\n",
    "gdp['year'] = [x.year for x in gdp.date]\n",
    "gdp['gdp_lag'] = gdp.GDP.shift()\n",
    "gdp['gdp_growth'] = (gdp.GDP - gdp.gdp_lag)/gdp.gdp_lag\n",
    "gdp = gdp[~gdp.gdp_growth.isna()]\n",
    "gdp_adf_p_value = adfuller(gdp.gdp_growth)[1]\n",
    "gdp_adf_p_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3406876459272497e-08"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10-year minus 2-year treasury rates\n",
    "t10y2y['date'] = [x.date() - dt.timedelta(days=1) for x in t10y2y.index]\n",
    "t10y2y = t10y2y[t10y2y['date'] <= dt.date(2020, 3, 1)]\n",
    "t10y2y['year'] = [x.year for x in t10y2y.date]\n",
    "t10y2y['month'] = [x.month for x in t10y2y.date]\n",
    "t10y2y = t10y2y.resample('ME').last()\n",
    "t10y2y = t10y2y[~t10y2y.T10Y2Y.isna()]\n",
    "t10y2y = t10y2y[t10y2y.month.isin([3,6,9,12])]\n",
    "\n",
    "t10y2y['t10y2y_lag'] = t10y2y.T10Y2Y.shift()\n",
    "t10y2y['t10y2y_growth'] = (t10y2y.T10Y2Y - t10y2y.t10y2y_lag)/t10y2y.t10y2y_lag\n",
    "t10y2y = t10y2y[~t10y2y.t10y2y_growth.isna()]\n",
    "t10y2y_adf_p_value = adfuller(t10y2y.t10y2y_growth)[1]\n",
    "t10y2y_adf_p_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008504485806052517"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Volatility, here we chose VIX\n",
    "vix['date'] = [x.date() - dt.timedelta(days=1) for x in vix.index]\n",
    "vix = vix[vix['date'] <= dt.date(2020, 3, 1)]\n",
    "vix['year'] = [x.year for x in vix.date]\n",
    "vix['month'] = [x.month for x in vix.date]\n",
    "vix = vix.resample('ME').last().dropna()\n",
    "vix = vix[~vix.VIXCLS.isna()]\n",
    "vix = vix[vix.month.isin([3,6,9,12])]\n",
    "\n",
    "vix['vix_lag'] = vix.VIXCLS.shift()\n",
    "vix['vix_growth'] = (vix.VIXCLS - vix.vix_lag)/vix.vix_lag\n",
    "vix = vix[~vix.vix_growth.isna()]\n",
    "vix_adf_p_value = adfuller(vix.vix_growth)[1]\n",
    "vix_adf_p_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the economic data with charge-off data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UNRATE        date  year  month  oil_price_growth  gdp_growth  \\\n",
      "0    -0.2  2000-03-31  2000      3               NaN    0.024549   \n",
      "1     0.2  2000-06-30  2000      6          0.316931    0.006874   \n",
      "2    -0.1  2000-09-30  2000      9         -0.100063    0.011395   \n",
      "3     0.3  2000-12-31  2000     12         -0.205489    0.003305   \n",
      "4     0.2  2001-03-31  2001      3          0.040744    0.012299   \n",
      "\n",
      "   t10y2y_growth  vix_growth  \n",
      "0            NaN         NaN  \n",
      "1      -0.255319   -0.189548  \n",
      "2      -0.485714    0.052712  \n",
      "3      -1.055556    0.305299  \n",
      "4      74.000000    0.066667  \n"
     ]
    }
   ],
   "source": [
    "economic_data = pd.merge(unrate, oil_price[['oil_price_growth','month','year']], how='left', on=['month','year'])\n",
    "\n",
    "economic_data = (\n",
    "    pd.merge(economic_data, gdp[['gdp_growth','month','year']], how='left', on=['month', 'year'])\n",
    "    .merge(t10y2y[['t10y2y_growth', 'month', 'year']], how='left', on=['month', 'year'])\n",
    "    .merge(vix[['vix_growth', 'month', 'year']], how='left', on=['month', 'year'])\n",
    ")\n",
    "\n",
    "print(economic_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UNRATE        date  year  month  oil_price_growth  gdp_growth  \\\n",
      "0    -0.2  2000-03-31  2000      3               NaN    0.024549   \n",
      "1     0.2  2000-06-30  2000      6          0.316931    0.006874   \n",
      "2    -0.1  2000-09-30  2000      9         -0.100063    0.011395   \n",
      "3     0.3  2000-12-31  2000     12         -0.205489    0.003305   \n",
      "4     0.2  2001-03-31  2001      3          0.040744    0.012299   \n",
      "\n",
      "   t10y2y_growth  vix_growth  card_chargeoff_pct  cre_chargeoff_pct  \n",
      "0            NaN         NaN                 NaN                NaN  \n",
      "1      -0.255319   -0.189548                 NaN                NaN  \n",
      "2      -0.485714    0.052712                 NaN                NaN  \n",
      "3      -1.055556    0.305299                 NaN                NaN  \n",
      "4      74.000000    0.066667            0.012672                NaN  \n"
     ]
    }
   ],
   "source": [
    "card_data['date'] = pd.to_datetime(card_data['date'])\n",
    "card_data['year'] = card_data['date'].dt.year\n",
    "card_data['month'] = card_data['date'].dt.month\n",
    "\n",
    "cre_data['date'] = pd.to_datetime(cre_data['date'])\n",
    "cre_data['year'] = cre_data['date'].dt.year\n",
    "cre_data['month'] = cre_data['date'].dt.month\n",
    "\n",
    "economic_data = pd.merge(economic_data, \n",
    "                      pd.merge(card_data[['card_chargeoff_pct', 'month', 'year']], \n",
    "                               cre_data[['cre_chargeoff_pct', 'month', 'year']], \n",
    "                               how='left', on=['month', 'year']),\n",
    "                      how='left', on=['month', 'year'])\n",
    "print(economic_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run all possible AR1, three factors model. (one lag and three factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lags for the charge-offs respectively\n",
    "economic_data['card_chargeoff_lag'] = economic_data['card_chargeoff_pct'].shift()\n",
    "economic_data['cre_chargeoff_lag'] = economic_data['cre_chargeoff_pct'].shift()\n",
    "\n",
    "# Create factors \n",
    "factors = ['UNRATE', 'oil_price_growth', 'gdp_growth', 't10y2y_growth', 'vix_growth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Card Model Factors: ('UNRATE', 'oil_price_growth', 'gdp_growth'), R-squared: 0.8667\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:     card_chargeoff_pct   R-squared:                       0.867\n",
      "Model:                            OLS   Adj. R-squared:                  0.859\n",
      "Method:                 Least Squares   F-statistic:                     113.8\n",
      "Date:                Fri, 11 Oct 2024   Prob (F-statistic):           7.28e-30\n",
      "Time:                        14:37:37   Log-Likelihood:                 373.72\n",
      "No. Observations:                  75   AIC:                            -737.4\n",
      "Df Residuals:                      70   BIC:                            -725.8\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "======================================================================================\n",
      "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "const                  0.0010      0.001      1.560      0.123      -0.000       0.002\n",
      "card_chargeoff_lag     0.8948      0.045     20.084      0.000       0.806       0.984\n",
      "UNRATE                 0.0022      0.001      3.372      0.001       0.001       0.003\n",
      "oil_price_growth       0.0014      0.001      1.307      0.195      -0.001       0.004\n",
      "gdp_growth             0.0282      0.032      0.870      0.387      -0.036       0.093\n",
      "==============================================================================\n",
      "Omnibus:                        5.210   Durbin-Watson:                   2.162\n",
      "Prob(Omnibus):                  0.074   Jarque-Bera (JB):                7.381\n",
      "Skew:                          -0.041   Prob(JB):                       0.0250\n",
      "Kurtosis:                       4.535   Cond. No.                         225.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "def ar1_models(data, dependent_var, lag_var, factors):\n",
    "    best_r_squared = -np.inf\n",
    "    best_model = None\n",
    "    best_factors = None\n",
    "\n",
    "    factor_combinations = list(combinations(factors, 3))\n",
    "\n",
    "    for combo in factor_combinations:\n",
    "        X_vars = [lag_var] + list(combo)\n",
    "        model_data = data[[dependent_var] + X_vars].dropna()\n",
    "\n",
    "        X = model_data[X_vars]\n",
    "        y = model_data[dependent_var]\n",
    "        X = sm.add_constant(X)\n",
    "\n",
    "        model = sm.OLS(y, X).fit()\n",
    "\n",
    "        if model.rsquared > best_r_squared: # Check if this model has the best R-squared so far\n",
    "            best_r_squared = model.rsquared\n",
    "            best_model = model\n",
    "            best_factors = combo\n",
    "\n",
    "    return best_factors, best_r_squared, best_model\n",
    "\n",
    "# AR1 model for card_chargeoff_pct\n",
    "best_card_factors, best_card_r_squared, best_card_model = ar1_models(\n",
    "    economic_data, 'card_chargeoff_pct', 'card_chargeoff_lag', factors\n",
    ")\n",
    "\n",
    "print(f\"Best Card Model Factors: {best_card_factors}, R-squared: {best_card_r_squared:.4f}\")\n",
    "print(best_card_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment on Results\n",
    "- The Card charge-offs model is quite strong, with an R-squared explaining 86.7% of the variance in charge-off percentages. \n",
    "- The model is driven mostly by the lagged dependent variable and the unemployment rate given both the Card charge-off lag and UNRATE have p-values less than 0.001, suggesting that the historical Card charge-off data and unemployment rate data are strong predictors of current charge-off rates.\n",
    "- However, oil price growth and GDP growth don't add much explanatory power given their p-values are greater than 0.05, even though the model fits the data well overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best CRE Model Factors: ('UNRATE', 'gdp_growth', 'vix_growth'), R-squared: 0.3709\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:      cre_chargeoff_pct   R-squared:                       0.371\n",
      "Model:                            OLS   Adj. R-squared:                  0.334\n",
      "Method:                 Least Squares   F-statistic:                     10.17\n",
      "Date:                Fri, 11 Oct 2024   Prob (F-statistic):           1.57e-06\n",
      "Time:                        14:37:37   Log-Likelihood:                 456.79\n",
      "No. Observations:                  74   AIC:                            -903.6\n",
      "Df Residuals:                      69   BIC:                            -892.1\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=====================================================================================\n",
      "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "const                 0.0002      0.000      1.721      0.090   -3.13e-05       0.000\n",
      "cre_chargeoff_lag    -0.5455      0.101     -5.378      0.000      -0.748      -0.343\n",
      "UNRATE                0.0006      0.000      2.714      0.008       0.000       0.001\n",
      "gdp_growth           -0.0181      0.010     -1.833      0.071      -0.038       0.002\n",
      "vix_growth           -0.0004      0.000     -2.320      0.023      -0.001   -5.64e-05\n",
      "==============================================================================\n",
      "Omnibus:                       17.583   Durbin-Watson:                   1.769\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               96.235\n",
      "Skew:                           0.141   Prob(JB):                     1.27e-21\n",
      "Kurtosis:                       8.580   Cond. No.                     1.67e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.67e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# AR1 models for cre_chargeoff_pct\n",
    "best_cre_factors, best_cre_r_squared, best_cre_model = ar1_models(\n",
    "    economic_data, 'cre_chargeoff_pct', 'cre_chargeoff_lag', factors\n",
    ")\n",
    "\n",
    "print(f\"\\nBest CRE Model Factors: {best_cre_factors}, R-squared: {best_cre_r_squared:.4f}\")\n",
    "print(best_cre_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment on Results\n",
    "- The CRE charge-offs model is weaker, with an R-squared explaining only 37.1% of the variance in charge-offs. \n",
    "- The lagged cre charge-offs, unemployment rate, and VIX growth are significant, the negative coefficients indicating that higher CRE charge-offs and volatility index in the previous period are associated with lower charge-offs in the current period. However, the high unemployment rate still slightly increase CRE charge-offs of the current period.\n",
    "- The model doesn't perform as well as the card charge-off model, indicating that other factors likely drive CRE charge-offs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment on what other factors might be useful for an exercise like this. Also, comment on what information you would need to make forecasts in the future using these models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some other factors that might improve the explanatory power of the models are:\n",
    "- Interest Rates: Loan interest rates are key drivers of consumer and commercial borrowing costs. Higher interest rates may increase default risks as debt servicing becomes more expensive.\n",
    "- Inflation Rates: Inflation affects the purchasing power of consumers and businesses. Rising inflation can lead to higher expenses, reducing the ability of borrowers to service debts.\n",
    "- Credit Spread: The spread between corporate bond yields and government bond yields is often used as a measure of credit risk. A widening spread may indicate higher default risk.\n",
    "\n",
    "Additional information needed to better forecast in the future:\n",
    "- Updated Macroeconomic Data: To make accurate forecasts, the model needs the most up-to-date data on all macroeconomic variables used in the model.\n",
    "- Scenario Projections and Stress Testings: We can use projected economic conditions such as expected changes in GDP, interest rates, inflation, and unemployment from the projections provided by central banks and credible financial institutions. Furthermore, stress testings under adverse economic conditions is also important to estimate how charge-offs might behave in worst-case scenarios.\n",
    "- Historical Data for Model Re-Estimation: Over time, the relationships between variables might change, requiring periodic re-estimation of the models to ensure they remain accurate and relevant. Updated datasets with longer histories will help refine and improve the model's predictive accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
